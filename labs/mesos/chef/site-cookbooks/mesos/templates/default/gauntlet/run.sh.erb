#/bin/sh

export KAFKA_SOURCE_TOPIC="dataset"
export KAFKA_DESTINATION_TOPIC="mirror_dataset"
export KAFKA_FETCH_SIZE="64"
export KAFKA_NUM_TOPIC_PARTITIONS="1"

export ZK_CONNECT="<%= @zk_servers.split(',').join(':2181,') %>:2181"

export SPARK_PATH="<%= @spark_install_dir %>"

export CASSANDRA_HOST="<%= @cassandra_servers %>"
export CASSANDRA_USER="cassandra"
export CASSANDRA_PASSWORD="cassandra"

$SPARK_PATH/bin/spark-submit --conf spark.cassandra.connection.host=$CASSANDRA_HOST \
--conf spark.cassandra.auth.username=$CASSANDRA_USER \
--conf spark.cassandra.auth.password=$CASSANDRA_PASSWORD \
--executor-memory 1G \
--total-executor-cores 1 \
--class ly.stealth.shaihulud.reader.Main \
spark-reader/build/libs/spark-reader-1.0.jar --source $KAFKA_SOURCE_TOPIC \
--destination $KAFKA_DESTINATION_TOPIC \
--partitions $KAFKA_NUM_TOPIC_PARTITIONS \
--zookeeper $ZK_CONNECT \
--kafka.fetch.size $KAFKA_FETCH_SIZE \
--testId $1 1> spark-reader.out 2> spark-reader.err &